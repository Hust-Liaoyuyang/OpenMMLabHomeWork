2023/06/09 23:56:21 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.16 (main, Mar  8 2023, 14:00:05) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 113905885
    GPU 0,1,2,3,4,5,6,7: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda-11.2
    NVCC: Cuda compilation tools, release 11.2, V11.2.152
    GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
    PyTorch: 1.12.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.13.1
    OpenCV: 4.7.0
    MMEngine: 0.7.4

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 113905885
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2023/06/09 23:56:21 - mmengine - INFO - Config:
default_scope = 'mmdet'
metainfo = dict(classes=('balloon', ))
NUM_CLASSES = 1
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=50),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(type='CheckpointHook', interval=10, max_keep_ckpts=3),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='DetVisualizationHook'))
env_cfg = dict(
    cudnn_benchmark=False,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
vis_backends = [dict(type='LocalVisBackend')]
visualizer = dict(
    type='DetLocalVisualizer',
    vis_backends=[dict(type='LocalVisBackend')],
    name='visualizer')
log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)
log_level = 'INFO'
load_from = 'https://download.openmmlab.com/mmrotate/v1.0/rotated_rtmdet/rotated_rtmdet_l-coco_pretrain-3x-dota_ms/rotated_rtmdet_l-coco_pretrain-3x-dota_ms-06d248a2.pth'
resume = False
train_cfg = dict(
    type='EpochBasedTrainLoop',
    max_epochs=300,
    val_interval=10,
    dynamic_intervals=[(280, 1)])
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')
param_scheduler = [
    dict(
        type='LinearLR', start_factor=1e-05, by_epoch=False, begin=0,
        end=1000),
    dict(
        type='CosineAnnealingLR',
        eta_min=0.0002,
        begin=150,
        end=300,
        T_max=150,
        by_epoch=True,
        convert_to_iter_based=True)
]
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(type='AdamW', lr=0.004, weight_decay=0.05),
    paramwise_cfg=dict(
        norm_decay_mult=0, bias_decay_mult=0, bypass_duplicate=True))
auto_scale_lr = dict(enable=False, base_batch_size=16)
dataset_type = 'CocoDataset'
data_root = '/home/LYY/workspace/pycharm/mmdetection/datasets/balloon'
backend_args = None
train_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='CachedMosaic', img_scale=(640, 640), pad_val=114.0),
    dict(
        type='RandomResize',
        scale=(1280, 1280),
        ratio_range=(0.1, 2.0),
        keep_ratio=True),
    dict(type='RandomCrop', crop_size=(640, 640)),
    dict(type='YOLOXHSVRandomAug'),
    dict(type='RandomFlip', prob=0.5),
    dict(type='Pad', size=(640, 640), pad_val=dict(img=(114, 114, 114))),
    dict(
        type='CachedMixUp',
        img_scale=(640, 640),
        ratio_range=(1.0, 1.0),
        max_cached_images=20,
        pad_val=(114, 114, 114)),
    dict(type='PackDetInputs')
]
test_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(type='Resize', scale=(640, 640), keep_ratio=True),
    dict(type='Pad', size=(640, 640), pad_val=dict(img=(114, 114, 114))),
    dict(
        type='PackDetInputs',
        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                   'scale_factor'))
]
train_dataloader = dict(
    batch_size=8,
    num_workers=5,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    batch_sampler=None,
    dataset=dict(
        type='CocoDataset',
        data_root='/home/LYY/workspace/pycharm/mmdetection/datasets/balloon',
        metainfo=dict(classes=('balloon', )),
        ann_file='train/balloon_train.json',
        data_prefix=dict(img='train/'),
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=[
            dict(type='LoadImageFromFile', backend_args=None),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='CachedMosaic', img_scale=(640, 640), pad_val=114.0),
            dict(
                type='RandomResize',
                scale=(1280, 1280),
                ratio_range=(0.1, 2.0),
                keep_ratio=True),
            dict(type='RandomCrop', crop_size=(640, 640)),
            dict(type='YOLOXHSVRandomAug'),
            dict(type='RandomFlip', prob=0.5),
            dict(
                type='Pad', size=(640, 640),
                pad_val=dict(img=(114, 114, 114))),
            dict(
                type='CachedMixUp',
                img_scale=(640, 640),
                ratio_range=(1.0, 1.0),
                max_cached_images=20,
                pad_val=(114, 114, 114)),
            dict(type='PackDetInputs')
        ],
        backend_args=None),
    pin_memory=True)
val_dataloader = dict(
    batch_size=5,
    num_workers=10,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='CocoDataset',
        data_root='/home/LYY/workspace/pycharm/mmdetection/datasets/balloon/',
        metainfo=dict(classes=('balloon', )),
        ann_file='val/balloon_val.json',
        data_prefix=dict(img='val/'),
        test_mode=True,
        pipeline=[
            dict(type='LoadImageFromFile', backend_args=None),
            dict(type='Resize', scale=(640, 640), keep_ratio=True),
            dict(
                type='Pad', size=(640, 640),
                pad_val=dict(img=(114, 114, 114))),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor'))
        ],
        backend_args=None))
test_dataloader = dict(
    batch_size=5,
    num_workers=10,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='CocoDataset',
        data_root='/home/LYY/workspace/pycharm/mmdetection/datasets/balloon/',
        metainfo=dict(classes=('balloon', )),
        ann_file='val/balloon_val.json',
        data_prefix=dict(img='val/'),
        test_mode=True,
        pipeline=[
            dict(type='LoadImageFromFile', backend_args=None),
            dict(type='Resize', scale=(640, 640), keep_ratio=True),
            dict(
                type='Pad', size=(640, 640),
                pad_val=dict(img=(114, 114, 114))),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor'))
        ],
        backend_args=None))
val_evaluator = dict(
    type='CocoMetric',
    ann_file=
    '/home/LYY/workspace/pycharm/mmdetection/datasets/balloon/val/balloon_val.json',
    metric='bbox',
    format_only=False,
    backend_args=None,
    proposal_nums=(100, 1, 10))
test_evaluator = dict(
    type='CocoMetric',
    ann_file=
    '/home/LYY/workspace/pycharm/mmdetection/datasets/balloon/val/balloon_val.json',
    metric='bbox',
    format_only=False,
    backend_args=None,
    proposal_nums=(100, 1, 10))
tta_model = dict(
    type='DetTTAModel',
    tta_cfg=dict(nms=dict(type='nms', iou_threshold=0.6), max_per_img=100))
img_scales = [(640, 640), (320, 320), (960, 960)]
tta_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(
        type='TestTimeAug',
        transforms=[[{
            'type': 'Resize',
            'scale': (640, 640),
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale': (320, 320),
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale': (960, 960),
            'keep_ratio': True
        }],
                    [{
                        'type': 'RandomFlip',
                        'prob': 1.0
                    }, {
                        'type': 'RandomFlip',
                        'prob': 0.0
                    }],
                    [{
                        'type': 'Pad',
                        'size': (960, 960),
                        'pad_val': {
                            'img': (114, 114, 114)
                        }
                    }],
                    [{
                        'type':
                        'PackDetInputs',
                        'meta_keys':
                        ('img_id', 'img_path', 'ori_shape', 'img_shape',
                         'scale_factor', 'flip', 'flip_direction')
                    }]])
]
model = dict(
    type='RTMDet',
    data_preprocessor=dict(
        type='DetDataPreprocessor',
        mean=[103.53, 116.28, 123.675],
        std=[57.375, 57.12, 58.395],
        bgr_to_rgb=False,
        batch_augments=None),
    backbone=dict(
        type='CSPNeXt',
        arch='P5',
        expand_ratio=0.5,
        deepen_factor=1,
        widen_factor=1,
        channel_attention=True,
        norm_cfg=dict(type='SyncBN'),
        act_cfg=dict(type='SiLU', inplace=True)),
    neck=dict(
        type='CSPNeXtPAFPN',
        in_channels=[256, 512, 1024],
        out_channels=256,
        num_csp_blocks=3,
        expand_ratio=0.5,
        norm_cfg=dict(type='SyncBN'),
        act_cfg=dict(type='SiLU', inplace=True)),
    bbox_head=dict(
        type='RTMDetSepBNHead',
        num_classes=1,
        in_channels=256,
        stacked_convs=2,
        feat_channels=256,
        anchor_generator=dict(
            type='MlvlPointGenerator', offset=0, strides=[8, 16, 32]),
        bbox_coder=dict(type='DistancePointBBoxCoder'),
        loss_cls=dict(
            type='QualityFocalLoss',
            use_sigmoid=True,
            beta=2.0,
            loss_weight=1.0),
        loss_bbox=dict(type='GIoULoss', loss_weight=2.0),
        with_objectness=False,
        exp_on_reg=True,
        share_conv=True,
        pred_kernel_size=1,
        norm_cfg=dict(type='SyncBN'),
        act_cfg=dict(type='SiLU', inplace=True)),
    train_cfg=dict(
        assigner=dict(type='DynamicSoftLabelAssigner', topk=13),
        allowed_border=-1,
        pos_weight=-1,
        debug=False),
    test_cfg=dict(
        nms_pre=30000,
        min_bbox_size=0,
        score_thr=0.001,
        nms=dict(type='nms', iou_threshold=0.65),
        max_per_img=300))
train_pipeline_stage2 = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='RandomResize',
        scale=(640, 640),
        ratio_range=(0.1, 2.0),
        keep_ratio=True),
    dict(type='RandomCrop', crop_size=(640, 640)),
    dict(type='YOLOXHSVRandomAug'),
    dict(type='RandomFlip', prob=0.5),
    dict(type='Pad', size=(640, 640), pad_val=dict(img=(114, 114, 114))),
    dict(type='PackDetInputs')
]
max_epochs = 300
stage2_num_epochs = 20
base_lr = 0.0004
interval = 10
custom_hooks = [
    dict(
        type='EMAHook',
        ema_type='ExpMomentumEMA',
        momentum=0.0002,
        update_buffers=True,
        priority=49),
    dict(
        type='PipelineSwitchHook',
        switch_epoch=280,
        switch_pipeline=[
            dict(type='LoadImageFromFile', backend_args=None),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='RandomResize',
                scale=(640, 640),
                ratio_range=(0.1, 2.0),
                keep_ratio=True),
            dict(type='RandomCrop', crop_size=(640, 640)),
            dict(type='YOLOXHSVRandomAug'),
            dict(type='RandomFlip', prob=0.5),
            dict(
                type='Pad', size=(640, 640),
                pad_val=dict(img=(114, 114, 114))),
            dict(type='PackDetInputs')
        ])
]
launcher = 'none'
work_dir = './work_dirs/balloon'

2023/06/09 23:56:24 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2023/06/09 23:56:24 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(49          ) EMAHook                            
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_load_checkpoint:
(49          ) EMAHook                            
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(49          ) EMAHook                            
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) PipelineSwitchHook                 
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(49          ) EMAHook                            
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(49          ) EMAHook                            
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(49          ) EMAHook                            
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_save_checkpoint:
(49          ) EMAHook                            
 -------------------- 
after_train:
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(49          ) EMAHook                            
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(49          ) EMAHook                            
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.4.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.4.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.4.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.4.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.4.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.4.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.5.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.5.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.5.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.5.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.5.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.5.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.4.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.4.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.4.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.4.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.4.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.4.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.5.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.5.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.5.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.5.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.5.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.5.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.2.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.2.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.2.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.2.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.2.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.2.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - WARNING - bbox_head.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - WARNING - bbox_head.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - WARNING - bbox_head.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - WARNING - bbox_head.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - WARNING - bbox_head.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - WARNING - bbox_head.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - WARNING - bbox_head.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - WARNING - bbox_head.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.weight:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.0.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.1.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.2.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.0.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.1.bias:weight_decay=0.0
2023/06/09 23:56:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.2.bias:weight_decay=0.0
Name of parameter - Initialization information

backbone.stem.0.conv.weight - torch.Size([32, 3, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.0.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.0.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.conv.weight - torch.Size([32, 32, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.conv.weight - torch.Size([64, 32, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.conv.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.conv.weight - torch.Size([64, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.main_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.conv.weight - torch.Size([64, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.short_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.final_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.conv.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv1.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([64, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.conv.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv1.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([64, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.2.conv1.conv.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.2.conv1.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.2.conv1.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([64, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.attention.fc.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.attention.fc.bias - torch.Size([128]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.conv.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.conv.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.main_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.conv.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.short_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.final_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([128, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([128, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([128, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([128, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.4.conv1.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.4.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.4.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.4.conv2.depthwise_conv.conv.weight - torch.Size([128, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.4.conv2.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.4.conv2.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.4.conv2.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.4.conv2.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.4.conv2.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.5.conv1.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.5.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.5.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.5.conv2.depthwise_conv.conv.weight - torch.Size([128, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.5.conv2.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.5.conv2.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.5.conv2.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.5.conv2.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.5.conv2.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.attention.fc.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.attention.fc.bias - torch.Size([256]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.conv.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.main_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.short_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.final_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.4.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.4.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.4.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.4.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.4.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.4.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.4.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.4.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.4.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.5.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.5.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.5.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.5.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.5.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.5.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.5.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.5.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.5.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.attention.fc.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.attention.fc.bias - torch.Size([512]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.conv.weight - torch.Size([1024, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.0.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.conv.weight - torch.Size([1024, 2048, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv2.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.main_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.short_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.conv.weight - torch.Size([1024, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.final_conv.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([512, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([512, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.2.conv1.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.2.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.2.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([512, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.attention.fc.weight - torch.Size([1024, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.attention.fc.bias - torch.Size([1024]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.conv.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.main_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.conv.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.short_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.final_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.2.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.2.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.2.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.conv.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.main_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.conv.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.short_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.final_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([128, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([128, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.2.conv1.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.2.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.2.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([128, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.main_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.short_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.final_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.2.conv1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.2.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.2.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([256, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.main_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.short_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.conv.weight - torch.Size([1024, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.final_conv.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([512, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([512, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.2.conv1.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.2.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.2.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([512, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.conv.weight - torch.Size([256, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.conv.weight - torch.Size([256, 1024, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.rtm_cls.0.weight - torch.Size([1, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.0.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.weight - torch.Size([1, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.weight - torch.Size([1, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.weight - torch.Size([4, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.weight - torch.Size([4, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.weight - torch.Size([4, 256, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  
2023/06/09 23:56:25 - mmengine - INFO - Load checkpoint from https://download.openmmlab.com/mmrotate/v1.0/rotated_rtmdet/rotated_rtmdet_l-coco_pretrain-3x-dota_ms/rotated_rtmdet_l-coco_pretrain-3x-dota_ms-06d248a2.pth
2023/06/09 23:56:25 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2023/06/09 23:56:25 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2023/06/09 23:56:25 - mmengine - INFO - Checkpoints will be saved to /home/LYY/workspace/pycharm/mmdetection/workdir/balloon/work_dirs/balloon.
2023/06/09 23:56:33 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:56:33 - mmengine - INFO - Epoch(train)   [1][8/8]  lr: 2.8068e-05  eta: 0:40:11  time: 1.0080  data_time: 0.4011  memory: 11374  loss: 2.4375  loss_cls: 1.5448  loss_bbox: 0.8928
2023/06/09 23:56:39 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:56:39 - mmengine - INFO - Epoch(train)   [2][8/8]  lr: 6.0099e-05  eta: 0:32:49  time: 0.8262  data_time: 0.3548  memory: 11372  loss: 2.4758  loss_cls: 1.6118  loss_bbox: 0.8640
2023/06/09 23:56:43 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:56:43 - mmengine - INFO - Epoch(train)   [3][8/8]  lr: 9.2131e-05  eta: 0:29:59  time: 0.7574  data_time: 0.3284  memory: 11372  loss: 2.4956  loss_cls: 1.6522  loss_bbox: 0.8434
2023/06/09 23:56:48 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:56:48 - mmengine - INFO - Epoch(train)   [4][8/8]  lr: 1.2416e-04  eta: 0:28:12  time: 0.7148  data_time: 0.3083  memory: 11386  loss: 2.5386  loss_cls: 1.7352  loss_bbox: 0.8034
2023/06/09 23:56:53 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:56:53 - mmengine - INFO - Epoch(train)   [5][8/8]  lr: 1.5619e-04  eta: 0:27:02  time: 0.6875  data_time: 0.2943  memory: 11373  loss: 2.5424  loss_cls: 1.7746  loss_bbox: 0.7678
2023/06/09 23:56:58 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:56:58 - mmengine - INFO - Epoch(train)   [6][8/8]  lr: 1.8823e-04  eta: 0:26:27  time: 0.6750  data_time: 0.2901  memory: 11373  loss: 2.4572  loss_cls: 1.7266  loss_bbox: 0.7306
2023/06/09 23:57:03 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:03 - mmengine - INFO - Epoch(train)   [7][8/8]  lr: 2.2026e-04  eta: 0:26:22  time: 0.6068  data_time: 0.2681  memory: 11370  loss: 2.3056  loss_cls: 1.6280  loss_bbox: 0.6776
2023/06/09 23:57:08 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:08 - mmengine - INFO - Epoch(train)   [8][8/8]  lr: 2.5229e-04  eta: 0:25:54  time: 0.5990  data_time: 0.2593  memory: 11374  loss: 2.0896  loss_cls: 1.4683  loss_bbox: 0.6212
2023/06/09 23:57:13 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:13 - mmengine - INFO - Epoch(train)   [9][8/8]  lr: 2.8432e-04  eta: 0:25:29  time: 0.5944  data_time: 0.2553  memory: 11382  loss: 1.8579  loss_cls: 1.2933  loss_bbox: 0.5647
2023/06/09 23:57:17 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:17 - mmengine - INFO - Epoch(train)  [10][8/8]  lr: 3.1635e-04  eta: 0:25:10  time: 0.5960  data_time: 0.2572  memory: 11377  loss: 1.5708  loss_cls: 1.0586  loss_bbox: 0.5122
2023/06/09 23:57:17 - mmengine - INFO - Saving checkpoint at 10 epochs
2023/06/09 23:57:20 - mmengine - INFO - Evaluating bbox...
2023/06/09 23:57:20 - mmengine - INFO - bbox_mAP_copypaste: 0.527 0.701 0.670 0.007 0.328 0.618
2023/06/09 23:57:20 - mmengine - INFO - Epoch(val) [10][3/3]    coco/bbox_mAP: 0.5270  coco/bbox_mAP_50: 0.7010  coco/bbox_mAP_75: 0.6700  coco/bbox_mAP_s: 0.0070  coco/bbox_mAP_m: 0.3280  coco/bbox_mAP_l: 0.6180  data_time: 0.1965  time: 0.2692
2023/06/09 23:57:25 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:25 - mmengine - INFO - Epoch(train)  [11][8/8]  lr: 3.4838e-04  eta: 0:24:46  time: 0.5932  data_time: 0.2548  memory: 11382  loss: 1.2860  loss_cls: 0.8076  loss_bbox: 0.4785
2023/06/09 23:57:30 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:30 - mmengine - INFO - Epoch(train)  [12][8/8]  lr: 3.8042e-04  eta: 0:24:39  time: 0.5974  data_time: 0.2598  memory: 11385  loss: 1.0619  loss_cls: 0.6143  loss_bbox: 0.4476
2023/06/09 23:57:35 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:35 - mmengine - INFO - Epoch(train)  [13][8/8]  lr: 4.1245e-04  eta: 0:24:22  time: 0.5810  data_time: 0.2435  memory: 11374  loss: 0.9186  loss_cls: 0.5026  loss_bbox: 0.4161
2023/06/09 23:57:39 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:39 - mmengine - INFO - Epoch(train)  [14][8/8]  lr: 4.4448e-04  eta: 0:24:10  time: 0.5804  data_time: 0.2434  memory: 11375  loss: 0.8255  loss_cls: 0.4377  loss_bbox: 0.3878
2023/06/09 23:57:44 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:44 - mmengine - INFO - Epoch(train)  [15][8/8]  lr: 4.7651e-04  eta: 0:24:02  time: 0.5847  data_time: 0.2479  memory: 11371  loss: 0.7539  loss_cls: 0.3925  loss_bbox: 0.3614
2023/06/09 23:57:49 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:49 - mmengine - INFO - Epoch(train)  [16][8/8]  lr: 5.0854e-04  eta: 0:23:56  time: 0.5886  data_time: 0.2519  memory: 11379  loss: 0.7114  loss_cls: 0.3701  loss_bbox: 0.3413
2023/06/09 23:57:54 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:54 - mmengine - INFO - Epoch(train)  [17][8/8]  lr: 5.4058e-04  eta: 0:23:45  time: 0.5930  data_time: 0.2564  memory: 11372  loss: 0.6793  loss_cls: 0.3539  loss_bbox: 0.3254
2023/06/09 23:57:59 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:57:59 - mmengine - INFO - Epoch(train)  [18][8/8]  lr: 5.7261e-04  eta: 0:23:37  time: 0.5887  data_time: 0.2510  memory: 11374  loss: 0.6430  loss_cls: 0.3339  loss_bbox: 0.3091
2023/06/09 23:58:04 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:04 - mmengine - INFO - Epoch(train)  [19][8/8]  lr: 6.0464e-04  eta: 0:23:29  time: 0.5926  data_time: 0.2537  memory: 11376  loss: 0.6228  loss_cls: 0.3204  loss_bbox: 0.3024
2023/06/09 23:58:08 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:08 - mmengine - INFO - Epoch(train)  [20][8/8]  lr: 6.3667e-04  eta: 0:23:22  time: 0.5951  data_time: 0.2564  memory: 11374  loss: 0.6133  loss_cls: 0.3182  loss_bbox: 0.2951
2023/06/09 23:58:08 - mmengine - INFO - Saving checkpoint at 20 epochs
2023/06/09 23:58:12 - mmengine - INFO - Evaluating bbox...
2023/06/09 23:58:12 - mmengine - INFO - bbox_mAP_copypaste: 0.703 0.876 0.847 0.038 0.516 0.803
2023/06/09 23:58:12 - mmengine - INFO - Epoch(val) [20][3/3]    coco/bbox_mAP: 0.7030  coco/bbox_mAP_50: 0.8760  coco/bbox_mAP_75: 0.8470  coco/bbox_mAP_s: 0.0380  coco/bbox_mAP_m: 0.5160  coco/bbox_mAP_l: 0.8030  data_time: 0.0713  time: 0.1343
2023/06/09 23:58:16 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:16 - mmengine - INFO - Epoch(train)  [21][8/8]  lr: 6.6870e-04  eta: 0:23:12  time: 0.5894  data_time: 0.2502  memory: 11377  loss: 0.5971  loss_cls: 0.3089  loss_bbox: 0.2882
2023/06/09 23:58:21 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:21 - mmengine - INFO - Epoch(train)  [22][8/8]  lr: 7.0073e-04  eta: 0:23:00  time: 0.5772  data_time: 0.2383  memory: 11376  loss: 0.5944  loss_cls: 0.3068  loss_bbox: 0.2876
2023/06/09 23:58:25 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:25 - mmengine - INFO - Epoch(train)  [23][8/8]  lr: 7.3277e-04  eta: 0:22:51  time: 0.5760  data_time: 0.2362  memory: 11370  loss: 0.5787  loss_cls: 0.2936  loss_bbox: 0.2851
2023/06/09 23:58:30 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:30 - mmengine - INFO - Epoch(train)  [24][8/8]  lr: 7.6480e-04  eta: 0:22:44  time: 0.5757  data_time: 0.2352  memory: 11372  loss: 0.5732  loss_cls: 0.2906  loss_bbox: 0.2826
2023/06/09 23:58:35 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:35 - mmengine - INFO - Epoch(train)  [25][8/8]  lr: 7.9683e-04  eta: 0:22:37  time: 0.5746  data_time: 0.2352  memory: 11372  loss: 0.5634  loss_cls: 0.2831  loss_bbox: 0.2803
2023/06/09 23:58:39 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:39 - mmengine - INFO - Epoch(train)  [26][8/8]  lr: 8.2886e-04  eta: 0:22:28  time: 0.5666  data_time: 0.2265  memory: 11374  loss: 0.5451  loss_cls: 0.2689  loss_bbox: 0.2762
2023/06/09 23:58:44 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:44 - mmengine - INFO - Epoch(train)  [27][8/8]  lr: 8.6089e-04  eta: 0:22:19  time: 0.5645  data_time: 0.2245  memory: 11370  loss: 0.5368  loss_cls: 0.2605  loss_bbox: 0.2764
2023/06/09 23:58:49 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:49 - mmengine - INFO - Epoch(train)  [28][8/8]  lr: 8.9292e-04  eta: 0:22:16  time: 0.5793  data_time: 0.2390  memory: 11376  loss: 0.5272  loss_cls: 0.2522  loss_bbox: 0.2750
2023/06/09 23:58:54 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:54 - mmengine - INFO - Epoch(train)  [29][8/8]  lr: 9.2496e-04  eta: 0:22:09  time: 0.5813  data_time: 0.2411  memory: 11386  loss: 0.5195  loss_cls: 0.2460  loss_bbox: 0.2735
2023/06/09 23:58:59 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:58:59 - mmengine - INFO - Epoch(train)  [30][8/8]  lr: 9.5699e-04  eta: 0:22:03  time: 0.5796  data_time: 0.2398  memory: 11376  loss: 0.5085  loss_cls: 0.2396  loss_bbox: 0.2689
2023/06/09 23:58:59 - mmengine - INFO - Saving checkpoint at 30 epochs
2023/06/09 23:59:01 - mmengine - INFO - Evaluating bbox...
2023/06/09 23:59:01 - mmengine - INFO - bbox_mAP_copypaste: 0.697 0.840 0.810 0.000 0.547 0.787
2023/06/09 23:59:01 - mmengine - INFO - Epoch(val) [30][3/3]    coco/bbox_mAP: 0.6970  coco/bbox_mAP_50: 0.8400  coco/bbox_mAP_75: 0.8100  coco/bbox_mAP_s: 0.0000  coco/bbox_mAP_m: 0.5470  coco/bbox_mAP_l: 0.7870  data_time: 0.0725  time: 0.1343
2023/06/09 23:59:06 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:06 - mmengine - INFO - Epoch(train)  [31][8/8]  lr: 9.8902e-04  eta: 0:21:56  time: 0.5777  data_time: 0.2367  memory: 11386  loss: 0.4970  loss_cls: 0.2316  loss_bbox: 0.2654
2023/06/09 23:59:10 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:10 - mmengine - INFO - Epoch(train)  [32][8/8]  lr: 1.0211e-03  eta: 0:21:48  time: 0.5777  data_time: 0.2368  memory: 11380  loss: 0.4933  loss_cls: 0.2291  loss_bbox: 0.2642
2023/06/09 23:59:15 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:15 - mmengine - INFO - Epoch(train)  [33][8/8]  lr: 1.0531e-03  eta: 0:21:44  time: 0.5864  data_time: 0.2450  memory: 11375  loss: 0.4947  loss_cls: 0.2288  loss_bbox: 0.2659
2023/06/09 23:59:20 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:20 - mmengine - INFO - Epoch(train)  [34][8/8]  lr: 1.0851e-03  eta: 0:21:42  time: 0.5889  data_time: 0.2481  memory: 11374  loss: 0.4968  loss_cls: 0.2296  loss_bbox: 0.2671
2023/06/09 23:59:25 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:25 - mmengine - INFO - Epoch(train)  [35][8/8]  lr: 1.1171e-03  eta: 0:21:35  time: 0.5869  data_time: 0.2458  memory: 11373  loss: 0.4942  loss_cls: 0.2277  loss_bbox: 0.2665
2023/06/09 23:59:30 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:30 - mmengine - INFO - Epoch(train)  [36][8/8]  lr: 1.1492e-03  eta: 0:21:27  time: 0.5827  data_time: 0.2408  memory: 11395  loss: 0.4887  loss_cls: 0.2231  loss_bbox: 0.2655
2023/06/09 23:59:34 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:34 - mmengine - INFO - Epoch(train)  [37][8/8]  lr: 1.1812e-03  eta: 0:21:22  time: 0.5846  data_time: 0.2438  memory: 11378  loss: 0.4962  loss_cls: 0.2283  loss_bbox: 0.2680
2023/06/09 23:59:39 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:39 - mmengine - INFO - Epoch(train)  [38][8/8]  lr: 1.2132e-03  eta: 0:21:14  time: 0.5858  data_time: 0.2446  memory: 11380  loss: 0.4974  loss_cls: 0.2275  loss_bbox: 0.2699
2023/06/09 23:59:43 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:43 - mmengine - INFO - Epoch(train)  [39][8/8]  lr: 1.2453e-03  eta: 0:21:06  time: 0.5740  data_time: 0.2339  memory: 11377  loss: 0.4923  loss_cls: 0.2245  loss_bbox: 0.2678
2023/06/09 23:59:48 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:48 - mmengine - INFO - Epoch(train)  [40][8/8]  lr: 1.2773e-03  eta: 0:21:00  time: 0.5631  data_time: 0.2207  memory: 11371  loss: 0.4804  loss_cls: 0.2166  loss_bbox: 0.2638
2023/06/09 23:59:48 - mmengine - INFO - Saving checkpoint at 40 epochs
2023/06/09 23:59:51 - mmengine - INFO - Evaluating bbox...
2023/06/09 23:59:51 - mmengine - INFO - bbox_mAP_copypaste: 0.685 0.870 0.799 0.010 0.599 0.755
2023/06/09 23:59:51 - mmengine - INFO - Epoch(val) [40][3/3]    coco/bbox_mAP: 0.6850  coco/bbox_mAP_50: 0.8700  coco/bbox_mAP_75: 0.7990  coco/bbox_mAP_s: 0.0100  coco/bbox_mAP_m: 0.5990  coco/bbox_mAP_l: 0.7550  data_time: 0.0705  time: 0.1317
2023/06/09 23:59:56 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/09 23:59:56 - mmengine - INFO - Epoch(train)  [41][8/8]  lr: 1.3093e-03  eta: 0:20:56  time: 0.5674  data_time: 0.2240  memory: 11384  loss: 0.4778  loss_cls: 0.2159  loss_bbox: 0.2619
2023/06/10 00:00:00 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:00 - mmengine - INFO - Epoch(train)  [42][8/8]  lr: 1.3414e-03  eta: 0:20:50  time: 0.5726  data_time: 0.2284  memory: 11371  loss: 0.4880  loss_cls: 0.2216  loss_bbox: 0.2664
2023/06/10 00:00:05 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:05 - mmengine - INFO - Epoch(train)  [43][8/8]  lr: 1.3734e-03  eta: 0:20:44  time: 0.5702  data_time: 0.2241  memory: 11372  loss: 0.4926  loss_cls: 0.2285  loss_bbox: 0.2640
2023/06/10 00:00:11 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:11 - mmengine - INFO - Epoch(train)  [44][8/8]  lr: 1.4054e-03  eta: 0:20:44  time: 0.5910  data_time: 0.2439  memory: 11384  loss: 0.5011  loss_cls: 0.2334  loss_bbox: 0.2677
2023/06/10 00:00:15 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:15 - mmengine - INFO - Epoch(train)  [45][8/8]  lr: 1.4375e-03  eta: 0:20:38  time: 0.5958  data_time: 0.2481  memory: 11385  loss: 0.5059  loss_cls: 0.2382  loss_bbox: 0.2677
2023/06/10 00:00:20 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:20 - mmengine - INFO - Epoch(train)  [46][8/8]  lr: 1.4695e-03  eta: 0:20:33  time: 0.6000  data_time: 0.2522  memory: 11385  loss: 0.5077  loss_cls: 0.2403  loss_bbox: 0.2675
2023/06/10 00:00:25 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:25 - mmengine - INFO - Epoch(train)  [47][8/8]  lr: 1.5015e-03  eta: 0:20:27  time: 0.5976  data_time: 0.2505  memory: 11390  loss: 0.5198  loss_cls: 0.2486  loss_bbox: 0.2712
2023/06/10 00:00:30 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:30 - mmengine - INFO - Epoch(train)  [48][8/8]  lr: 1.5336e-03  eta: 0:20:23  time: 0.6002  data_time: 0.2536  memory: 11370  loss: 0.5121  loss_cls: 0.2435  loss_bbox: 0.2687
2023/06/10 00:00:35 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:35 - mmengine - INFO - Epoch(train)  [49][8/8]  lr: 1.5656e-03  eta: 0:20:17  time: 0.6031  data_time: 0.2569  memory: 11378  loss: 0.5105  loss_cls: 0.2390  loss_bbox: 0.2715
2023/06/10 00:00:39 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:39 - mmengine - INFO - Epoch(train)  [50][8/8]  lr: 1.5976e-03  eta: 0:20:11  time: 0.5819  data_time: 0.2376  memory: 11385  loss: 0.5037  loss_cls: 0.2339  loss_bbox: 0.2698
2023/06/10 00:00:39 - mmengine - INFO - Saving checkpoint at 50 epochs
2023/06/10 00:00:42 - mmengine - INFO - Evaluating bbox...
2023/06/10 00:00:42 - mmengine - INFO - bbox_mAP_copypaste: 0.645 0.840 0.759 0.163 0.415 0.745
2023/06/10 00:00:42 - mmengine - INFO - Epoch(val) [50][3/3]    coco/bbox_mAP: 0.6450  coco/bbox_mAP_50: 0.8400  coco/bbox_mAP_75: 0.7590  coco/bbox_mAP_s: 0.1630  coco/bbox_mAP_m: 0.4150  coco/bbox_mAP_l: 0.7450  data_time: 0.0700  time: 0.1295
2023/06/10 00:00:46 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:46 - mmengine - INFO - Epoch(train)  [51][8/8]  lr: 1.6297e-03  eta: 0:20:06  time: 0.5842  data_time: 0.2404  memory: 11372  loss: 0.5028  loss_cls: 0.2329  loss_bbox: 0.2699
2023/06/10 00:00:51 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:51 - mmengine - INFO - Epoch(train)  [52][8/8]  lr: 1.6617e-03  eta: 0:20:00  time: 0.5794  data_time: 0.2354  memory: 11375  loss: 0.5032  loss_cls: 0.2329  loss_bbox: 0.2703
2023/06/10 00:00:56 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:00:56 - mmengine - INFO - Epoch(train)  [53][8/8]  lr: 1.6937e-03  eta: 0:19:55  time: 0.5806  data_time: 0.2355  memory: 11379  loss: 0.4928  loss_cls: 0.2234  loss_bbox: 0.2694
2023/06/10 00:01:01 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:01:01 - mmengine - INFO - Epoch(train)  [54][8/8]  lr: 1.7257e-03  eta: 0:19:50  time: 0.5773  data_time: 0.2327  memory: 11374  loss: 0.4845  loss_cls: 0.2167  loss_bbox: 0.2678
2023/06/10 00:01:05 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:01:05 - mmengine - INFO - Epoch(train)  [55][8/8]  lr: 1.7578e-03  eta: 0:19:45  time: 0.5779  data_time: 0.2330  memory: 11394  loss: 0.4824  loss_cls: 0.2141  loss_bbox: 0.2682
2023/06/10 00:01:10 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:01:10 - mmengine - INFO - Epoch(train)  [56][8/8]  lr: 1.7898e-03  eta: 0:19:39  time: 0.5799  data_time: 0.2352  memory: 11378  loss: 0.4748  loss_cls: 0.2087  loss_bbox: 0.2661
2023/06/10 00:01:15 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:01:15 - mmengine - INFO - Epoch(train)  [57][8/8]  lr: 1.8218e-03  eta: 0:19:37  time: 0.5921  data_time: 0.2457  memory: 11374  loss: 0.4819  loss_cls: 0.2100  loss_bbox: 0.2719
2023/06/10 00:01:20 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:01:20 - mmengine - INFO - Epoch(train)  [58][8/8]  lr: 1.8539e-03  eta: 0:19:31  time: 0.5941  data_time: 0.2475  memory: 11394  loss: 0.4806  loss_cls: 0.2050  loss_bbox: 0.2757
2023/06/10 00:01:25 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:01:25 - mmengine - INFO - Epoch(train)  [59][8/8]  lr: 1.8859e-03  eta: 0:19:26  time: 0.5943  data_time: 0.2481  memory: 11378  loss: 0.4818  loss_cls: 0.2051  loss_bbox: 0.2767
2023/06/10 00:01:30 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:01:30 - mmengine - INFO - Epoch(train)  [60][8/8]  lr: 1.9179e-03  eta: 0:19:23  time: 0.6022  data_time: 0.2571  memory: 11373  loss: 0.4822  loss_cls: 0.2064  loss_bbox: 0.2758
2023/06/10 00:01:30 - mmengine - INFO - Saving checkpoint at 60 epochs
2023/06/10 00:01:33 - mmengine - INFO - Evaluating bbox...
2023/06/10 00:01:33 - mmengine - INFO - bbox_mAP_copypaste: 0.681 0.842 0.810 0.013 0.489 0.771
2023/06/10 00:01:33 - mmengine - INFO - Epoch(val) [60][3/3]    coco/bbox_mAP: 0.6810  coco/bbox_mAP_50: 0.8420  coco/bbox_mAP_75: 0.8100  coco/bbox_mAP_s: 0.0130  coco/bbox_mAP_m: 0.4890  coco/bbox_mAP_l: 0.7710  data_time: 0.0722  time: 0.1338
2023/06/10 00:01:38 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:01:38 - mmengine - INFO - Epoch(train)  [61][8/8]  lr: 1.9500e-03  eta: 0:19:18  time: 0.6066  data_time: 0.2617  memory: 11373  loss: 0.4745  loss_cls: 0.2035  loss_bbox: 0.2710
2023/06/10 00:01:42 - mmengine - INFO - Exp name: rtmdet_l_8xb32-300e_coco_20230609_235620
2023/06/10 00:01:42 - mmengine - INFO - Epoch(train)  [62][8/8]  lr: 1.9820e-03  eta: 0:19:12  time: 0.6024  data_time: 0.2579  memory: 11372  loss: 0.4749  loss_cls: 0.2047  loss_bbox: 0.2702
